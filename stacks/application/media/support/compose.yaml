###############################################################################
# Media Stack — Supporting Services
#
# Services: Bazarr, Tautulli, Maintainerr, Recyclarr, Seerr, Wizarr
# Tier: Application (depends on Infrastructure + Platform + Media Core)
# Spec: specs/007-media-stack-migration
# ADR: ADR-0033 Phase 3, ADR-0034 (labels), ADR-0035 (secrets)
###############################################################################

services:
  # ── Secret Hydration (one-shot job) ──────────────────────────
  op-secrets:
    image: 1password/op:2
    deploy:
      mode: replicated-job
      restart_policy:
        condition: none
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
    environment:
      OP_CONNECT_HOST: http://op-connect-api:8080
      OP_CONNECT_TOKEN_FILE: /run/secrets/op_connect_token
    secrets:
      - op_connect_token
    volumes:
      - ./support.env.template:/templates/support.template:ro
      - /mnt/apps01/appdata/media/support/secrets:/secrets
    networks:
      - op-connect
    command: >
      sh -ec "
      export OP_CONNECT_TOKEN=$$(cat /run/secrets/op_connect_token) &&
      op inject -i /templates/support.template -o /secrets/support.env -f &&
      chmod 644 /secrets/support.env &&
      echo 'Secrets injected successfully'
      "

  # ── Recyclarr ────────────────────────────────────────────────
  # Syncs TRaSH Guides quality profiles to Sonarr/Radarr (one-shot per deploy)
  recyclarr:
    image: ghcr.io/recyclarr/recyclarr:latest
    deploy:
      mode: replicated-job
      restart_policy:
        condition: none
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
    user: "1701:1702"
    volumes:
      - /mnt/apps01/appdata/media/recyclarr/config:/config
    networks:
      - proxy_network
    command: sync

  # ── Bazarr ───────────────────────────────────────────────────
  # Pinned to barbary — SQLite DB, no postgres support
  bazarr:
    image: lscr.io/linuxserver/bazarr:latest
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.hostname == barbary
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
      labels:
        # Homepage: Media dashboard
        homepage.group: "Media"
        homepage.name: "Bazarr"
        homepage.icon: "bazarr.png"
        homepage.href: "https://bazarr.in.hypyr.space"
        homepage.description: "Subtitle management"
        homepage.widget.type: "bazarr"
        homepage.widget.url: "http://bazarr:6767"

        # Caddy: Reverse proxy + Authentik forward auth
        caddy: bazarr.in.hypyr.space
        caddy.reverse_proxy: "{{upstreams 6767}}"
        caddy.tls.dns: "cloudflare {env.CLOUDFLARE_API_TOKEN}"
        caddy.forward_auth: "http://authentik-server:9000"
        caddy.forward_auth.uri: "/outpost.goauthentik.io/auth/caddy"
        caddy.forward_auth.copy_headers: "X-Authentik-Username X-Authentik-Groups X-Authentik-Email X-Authentik-Name X-Authentik-Uid"

        # AutoKuma: Uptime monitoring
        kuma.bazarr.http.name: "Bazarr"
        kuma.bazarr.http.url: "https://bazarr.in.hypyr.space/ping"
        kuma.bazarr.http.interval: "60"
        kuma.bazarr.http.maxretries: "3"
    environment:
      PUID: "1701"
      PGID: "1702"
      TZ: "America/Chicago"
    volumes:
      - /mnt/apps01/appdata/media/bazarr/config:/config
      - /mnt/data01/data:/data
    networks:
      - media_support
      - proxy_network

  # ── Tautulli ─────────────────────────────────────────────────
  # Pinned to barbary — SQLite DB, Plex-adjacent
  tautulli:
    image: lscr.io/linuxserver/tautulli:latest
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.hostname == barbary
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
      labels:
        # Homepage: Media dashboard
        homepage.group: "Media"
        homepage.name: "Tautulli"
        homepage.icon: "tautulli.png"
        homepage.href: "https://tautulli.in.hypyr.space"
        homepage.description: "Plex monitoring & analytics"
        homepage.widget.type: "tautulli"
        homepage.widget.url: "http://tautulli:8181"

        # Caddy: Reverse proxy + Authentik forward auth
        caddy: tautulli.in.hypyr.space
        caddy.reverse_proxy: "{{upstreams 8181}}"
        caddy.tls.dns: "cloudflare {env.CLOUDFLARE_API_TOKEN}"
        caddy.forward_auth: "http://authentik-server:9000"
        caddy.forward_auth.uri: "/outpost.goauthentik.io/auth/caddy"
        caddy.forward_auth.copy_headers: "X-Authentik-Username X-Authentik-Groups X-Authentik-Email X-Authentik-Name X-Authentik-Uid"

        # AutoKuma: Uptime monitoring
        kuma.tautulli.http.name: "Tautulli"
        kuma.tautulli.http.url: "https://tautulli.in.hypyr.space/status"
        kuma.tautulli.http.interval: "60"
        kuma.tautulli.http.maxretries: "3"
    environment:
      PUID: "1701"
      PGID: "1702"
      TZ: "America/Chicago"
    volumes:
      - /mnt/apps01/appdata/media/tautulli/config:/config
    networks:
      - media_support
      - proxy_network

  # ── Maintainerr ──────────────────────────────────────────────
  # Pinned to barbary — SQLite DB
  maintainerr:
    image: ghcr.io/jorenn92/maintainerr:latest
    user: "1701:1702"
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.hostname == barbary
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
      labels:
        # Homepage: Media dashboard
        homepage.group: "Media"
        homepage.name: "Maintainerr"
        homepage.icon: "maintainerr.png"
        homepage.href: "https://maintainerr.in.hypyr.space"
        homepage.description: "Plex library maintenance"

        # Caddy: Reverse proxy + Authentik forward auth
        caddy: maintainerr.in.hypyr.space
        caddy.reverse_proxy: "{{upstreams 6246}}"
        caddy.tls.dns: "cloudflare {env.CLOUDFLARE_API_TOKEN}"
        caddy.forward_auth: "http://authentik-server:9000"
        caddy.forward_auth.uri: "/outpost.goauthentik.io/auth/caddy"
        caddy.forward_auth.copy_headers: "X-Authentik-Username X-Authentik-Groups X-Authentik-Email X-Authentik-Name X-Authentik-Uid"

        # AutoKuma: Uptime monitoring
        kuma.maintainerr.http.name: "Maintainerr"
        kuma.maintainerr.http.url: "https://maintainerr.in.hypyr.space"
        kuma.maintainerr.http.interval: "60"
        kuma.maintainerr.http.maxretries: "3"
        kuma.maintainerr.http.accepted_statuscodes: '["200-299","301","302"]'
    volumes:
      - /mnt/apps01/appdata/media/maintainerr/config:/opt/data
    networks:
      - media_support
      - proxy_network

  # ── Seerr ────────────────────────────────────────────────────
  # Floats freely — state in PostgreSQL
  # Media request management (formerly Jellyseerr)
  seerr:
    image: ghcr.io/seerr-team/seerr:v3.0.0
    init: true
    group_add:
      - "999"
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
      labels:
        # Homepage: Media dashboard
        homepage.group: "Media"
        homepage.name: "Seerr"
        homepage.icon: "seerr.png"
        homepage.href: "https://requests.in.hypyr.space"
        homepage.description: "Media requests"
        homepage.widget.type: "overseerr"
        homepage.widget.url: "http://seerr:5055"

        # Caddy: Reverse proxy (NO forward auth — Seerr has own auth via Plex/Jellyfin)
        caddy: requests.in.hypyr.space
        caddy.reverse_proxy: "{{upstreams 5055}}"
        caddy.tls.dns: "cloudflare {env.CLOUDFLARE_API_TOKEN}"

        # AutoKuma: Uptime monitoring
        kuma.seerr.http.name: "Seerr"
        kuma.seerr.http.url: "https://requests.in.hypyr.space"
        kuma.seerr.http.interval: "60"
        kuma.seerr.http.maxretries: "3"
        kuma.seerr.http.accepted_statuscodes: '["200-299","301","302"]'
    environment:
      DB_TYPE: postgres
      DB_HOST: postgresql
      DB_PORT: "5432"
      DB_NAME: seerr
    volumes:
      - /mnt/apps01/appdata/media/seerr/config:/app/config
      - /mnt/apps01/appdata/media/support/secrets:/secrets:ro
    networks:
      - media_support
      - proxy_network
      - postgres
    entrypoint: ["/bin/sh", "-c"]
    command: >
      "set -a && [ -f /secrets/support.env ] && . /secrets/support.env && set +a &&
       exec npm start"

  # ── Wizarr ──────────────────────────────────────────────────
  # Pinned to barbary — SQLite DB
  # User invitation & onboarding for Plex/Jellyfin
  wizarr:
    image: ghcr.io/wizarrrr/wizarr:latest
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.hostname == barbary
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
      labels:
        # Homepage: Media dashboard
        homepage.group: "Media"
        homepage.name: "Wizarr"
        homepage.icon: "wizarr.png"
        homepage.href: "https://invite.in.hypyr.space"
        homepage.description: "User invitations"

        # Caddy: Reverse proxy (no forward auth — invite links must be public)
        caddy: invite.in.hypyr.space
        caddy.reverse_proxy: "{{upstreams 5690}}"
        caddy.tls.dns: "cloudflare {env.CLOUDFLARE_API_TOKEN}"

        # AutoKuma: Uptime monitoring
        kuma.wizarr.http.name: "Wizarr"
        kuma.wizarr.http.url: "https://invite.in.hypyr.space"
        kuma.wizarr.http.interval: "60"
        kuma.wizarr.http.maxretries: "3"
        kuma.wizarr.http.accepted_statuscodes: '["200-299","301","302"]'
    environment:
      TZ: "America/Chicago"
    volumes:
      - /mnt/apps01/appdata/media/wizarr/database:/data/database
    networks:
      - media_support
      - proxy_network

# ── Networks ─────────────────────────────────────────────────
networks:
  media_support:
    driver: overlay
  proxy_network:
    external: true
  postgres:
    name: platform_postgres_postgres
    external: true
  op-connect:
    name: op-connect_op-connect
    external: true

# ── Secrets ──────────────────────────────────────────────────
secrets:
  op_connect_token:
    external: true

